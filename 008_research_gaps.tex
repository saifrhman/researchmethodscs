\section{Research Gaps}
\subsection{Regional Bias}
Most mangrove modelling studies train and evaluate models within a single geographic region. When such models are applied to new regions, performance degradation is expected due to domain shift arising from differences in species composition, canopy structure, sediment characteristics, tidal regimes, and anthropogenic pressures. These factors induce systematic variation in optical reflectance, SAR backscatter, thermal signatures, and structural metrics, resulting in both covariate and concept shift across regions \cite{li_mapping_2021}, \cite{leal_state_2024}.

Despite these known challenges, explicit cross-region evaluation remains uncommon in the mangrove literature. Only isolated studies have examined transfer learning or domain adaptation, often focusing on narrow biophysical targets such as biochemical traits rather than holistic ecosystem properties (Wu et al., 2025)\cite{fu_cross-scenario_2025}. Consequently, reported model performance metrics may overestimate generalisability and mask sensitivity to regional heterogeneity.%TODO ADD CITATIONS!!!! Wu et al!

This imbalance has direct implications for restoration-oriented applications. Models trained predominantly on data rich regions, particularly in Asia, risk encoding region specific correlations rather than ecologically invariant representations. Addressing regional bias is therefore essential for both scientific validity and scalability, requiring systematic cross region benchmarking, transfer learning strategies, and domain aware evaluation protocols.

[Figure 4 placeholder: Global distribution of mangrove studies and regional data availability]

\subsection{Lack of a Unified Multimodal Forest Framework}
A second major research gap is the absence of a unified multimodal forest framework capable of integrating complementary geospatial data sources into a coherent and ecologically meaningful representation of mangrove ecosystems.

Each sensing modality captures a distinct and non-redundant component of forest condition:

\begin{itemize}
  \item Optical multispectral imagery encodes extent, canopy cover, and phenology \cite{bunting_global_2022}.
  \item SAR captures structure, moisture, and inundation dynamics under all-weather conditions \cite{ghorbanian_weakly_2025}.
  \item LiDAR provides direct measurements of three-dimensional canopy architecture and biomass \cite{li_mapping_2021}.
  \item Thermal infrared data reveal physiological stress and hydrological anomalies \cite{farella_thermal_2022}.
  \item Hyperspectral data support biochemical and species-level trait estimation \cite{fu_cross-scenario_2025}.
\end{itemize}

Single-modality analyses can therefore produce misleading restoration assessments. Intact canopy cover inferred from optical imagery may obscure physiological stress detectable in thermal data, while LiDAR-derived height alone does not capture hydrological constraints or salinity stress. Restoration decisions based on incomplete representations risk misidentifying resilient forests or prioritising unsuitable restoration sites.

Recent advances in multimodal representation learning offer a pathway toward addressing this limitation. Li et al. (2021) demonstrated that integrating multispectral, hyperspectral, and LiDAR data improves multilayer structural mapping, while Bahaduri et al. (2024) showed that channel-level cross-attention enables dynamic alignment between heterogeneous modalities. Channel-level fusion is particularly advantageous in mangrove ecosystems, where data relevance varies spatially and temporally due to cloud cover, tidal state, and sensor availability.

Figure 5 illustrates a conceptual unified multimodal framework for integrating spatiotemporal optical, SAR, LiDAR, thermal infrared, and multispectral or hyperspectral data into a shared latent forest representation, informed by the multimodal integration strategy proposed by Li et al. (2021).

\begin{figure}[ht]
\centering
\includegraphics[width=0.9\linewidth]{Figures/unified_framework.png}
\caption{Draft of what a unified multimodal framework for mangrove ecosystem surveying would look like \cite{li_mapping_2021}.}
\label{fig:unified_framework}
\end{figure}

Importantly, this review does not advocate a single architectural solution. Rather, it highlights that a holistic representation of mangrove ecosystem condition cannot be obtained from any single sensing modality, as key attributes such as extent, structure, hydrology, physiological stress, and biochemical composition are captured across complementary optical, SAR, LiDAR, thermal infrared, and multispectral or hyperspectral data sources. Cross-attention transformers, multimodal convolutional networks, graph-based models, hybrid ConvLSTM-Transformer pipelines, and ensemble approaches all represent viable computational pathways depending on data availability and restoration objectives. The central gap lies not in the absence of individual techniques, but in the lack of end-to-end, restoration-oriented multimodal frameworks explicitly designed to fuse these complementary modalities into generalisable and decision-relevant mangrove ecosystem representations.

\subsection{Limitations of CNN-Centric Approaches in Fragmented Mangrove Landscapes}

Convolutional neural networks underpin most deep learning-based mangrove classification and segmentation pipelines. While effective for large, contiguous forest stands, CNN-based approaches often struggle to detect small, fragmented, or linear mangrove patches embedded within complex coastal environments. This limitation is particularly pronounced in regions experiencing urbanisation, aquaculture expansion, or partial degradation.

Fragmentation-related challenges arise from three interconnected factors: reduced spatial context at fixed receptive field sizes, spectral confusion with surrounding vegetation or built environments, and heavy reliance on dense manual annotations. These issues contribute to reduced robustness when models are transferred to regions with differing fragmentation patterns. Addressing this gap will require exploration of multi-scale architectures, weakly supervised or semi-supervised learning strategies, and alternative spatial representations that better capture fine-grained ecological structure.

\subsection{Inadequate Observation of Submerged and Underwater Mangrove Components}

Most satellite-based mangrove monitoring relies on visible and near-infrared wavelengths, which are strongly attenuated by water, limiting detection of submerged root structures and early-stage regeneration in intertidal and subtidal zones. As a result, below-water components critical to ecosystem stability and recovery are often poorly characterised or entirely omitted from restoration assessments.

This sensing limitation constrains evaluation of mangrove health and restoration potential in tidally dynamic and turbid environments. Addressing this gap will require integration of alternative observation strategies, including UAV-based surveys, bathymetric and acoustic data, and improved fusion of radar and optical observations across tidal states.

\subsection{Limited Integration of Field Validation and Local Knowledge}

Despite advances in geospatial modelling, field validation and local ecological knowledge remain insufficiently integrated into many mangrove restoration studies. In situ observations are essential for validating remotely sensed classifications, contextualising model outputs, and identifying site-specific constraints that may not be captured by remote sensing alone.

The absence of systematic field validation can result in restoration suitability maps that are technically accurate yet ecologically or socially misaligned. Future frameworks should therefore emphasise participatory validation, integration of field measurements, and collaboration with local stakeholders to ensure that computational outputs translate into context-aware and implementable restoration decisions.